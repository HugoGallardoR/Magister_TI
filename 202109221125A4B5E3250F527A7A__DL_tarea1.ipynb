{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "202109221125A4B5E3250F527A7A__DL_tarea1.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HugoGallardoR/Magister_TI/blob/main/202109221125A4B5E3250F527A7A__DL_tarea1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g2cmRd0lnU69"
      },
      "source": [
        "# **Clasificación de Documentos**\n",
        "En este notebook, experimentarás con el dataset Reuters. Reuters es un dataset de documentos en donde cada documento es representado por un conjunto de palabras desde un vocabulario. El dataset contiene 46 clases. Usaremos un método conveniente de Keras colo para obtener el dataset:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPQnbFWwVWvG"
      },
      "source": [
        "from tensorflow.keras.datasets import reuters\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "import random\n",
        "import time"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7dDEWclKuAk2"
      },
      "source": [
        "Obtenemos el dataset y especificamos el número de palabras del vocaulario original que queremos usar. Este número se convertirá en la dimensión de nuestros datos. La función de Keras retorna un array de listas, donde cada lista es una secuencia de índices de palabras en un documento. Por ejemplo, la secuencia [1, 5, 8] significa que las palabras 1, 5, y 8 están contenidas en el documento. Para pre-procesar esta data, la convertiremos en un one-hot encoding (un vector que contiene un valor 1 en la palabra que aparece en el documento)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk4dgSHuV1jt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4dfed03f-be34-4e15-8528-5326dbda73be"
      },
      "source": [
        "def to_one_hot(sequences, dimension):\n",
        "    results = np.zeros((len(sequences), dimension))\n",
        "    for i, sequence in enumerate(sequences):\n",
        "        results[i, sequence] = 1\n",
        "    return results\n",
        "    \n",
        "(train_data, train_labels), (test_data, test_labels) = reuters.load_data(num_words = 10000)\n",
        "train_data = to_one_hot(train_data, 10000)\n",
        "test_data = to_one_hot(test_data, 10000)\n",
        "\n",
        "train_data = train_data.astype(np.float32)\n",
        "test_data = test_data.astype(np.float32)\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/reuters.npz\n",
            "2113536/2110848 [==============================] - 0s 0us/step\n",
            "2121728/2110848 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4L_Q-tbcmh1d"
      },
      "source": [
        "Ahora la data tiene la forma de una matriz con dimensiones NxM, donde N es la cantidad de muestras y M es la dimensión de cada muestra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1YHLnZRmsP9",
        "outputId": "1074c52e-a710-4212-bc83-c22e51dcd6ed"
      },
      "source": [
        "print(f'Tamaño de datos de entrenamiento: {train_data.shape}')\n",
        "print(f'Tamaño de datos de test: {test_data.shape}')\n",
        "\n",
        "#Existen 8982 muestras para entrenamiento y 2246 muestras para test"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tamaño de datos de entrenamiento: (8982, 10000)\n",
            "Tamaño de datos de test: (2246, 10000)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_iFxcUJ3zyR1"
      },
      "source": [
        "## **Tarea**\n",
        "El objetivo de esta tarea es implementar una red neuronal en Pytorch que nos permita clasificar el dataset Reuters. La red neuronal implementada debe alcanzar al menos un accuracy de 35% sobre el conjunto de test."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhdyD7TInMTd"
      },
      "source": [
        "## 1. Preparar la data\n",
        "Empezaremos por preparar la data para poder usarla en Pytorch. Para eso haremos uso de los DataLoaders. En el código inicial, el tamaño de batch está configurado en 1, pero puedes cambiar este valor y experimentar (se sugiere usar valores de batch_size más grandes que uno)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OnII2BMBTs2"
      },
      "source": [
        "import torch.utils.data as data\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "\n",
        "#Se comienza utilizando un batch_size de 10\n",
        "train_loader = data.DataLoader(list(zip(train_data, train_labels)), shuffle=True, batch_size=100)\n",
        "test_loader = data.DataLoader(list(zip(test_data, test_labels)), batch_size=100)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wTXydqDTjFcw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a849f15-0dde-4359-d36f-042310ae7364"
      },
      "source": [
        "# Cuando iteramos sobre el loader, obtenemos cada mini-batch y lo mostramos en pantalla\n",
        "# Cada mini-batch es un conjunto de muestras con su respectivo conjunto de etiquetas\n",
        "for sample in test_loader:\n",
        "  print(sample)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 3, 10,  1,  4,  4,  3,  3,  3,  3,  3,  5,  4,  1,  3,  1, 11, 23,  3,\n",
            "        19,  3,  8,  3,  3,  3,  9,  3,  4,  6, 10,  3,  3, 10, 20,  1, 19,  4,\n",
            "        40,  1,  4,  3, 15, 21,  3, 34,  4,  4,  3,  4,  3, 11, 20,  3,  1,  3,\n",
            "         3,  4, 26,  4, 20, 19,  4,  3,  4,  4,  4,  3,  3,  1,  3,  4, 21, 16,\n",
            "         3, 19, 43,  2,  1,  3, 39,  4,  3,  3,  3, 11, 19, 20,  1, 11,  4,  3,\n",
            "         3,  4,  3,  4,  3, 11, 11,  3, 20, 28])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 8,  1, 20,  3,  3,  2,  4,  4,  4,  4,  3,  3,  4,  3, 33,  3,  4,  4,\n",
            "         3,  4,  3,  4, 19,  4, 18,  3, 19,  3,  3,  3, 19,  3,  1,  3, 23,  4,\n",
            "        13,  1,  3,  3,  3,  3,  4,  4, 19,  4,  4, 24,  3,  3, 11,  4,  3,  3,\n",
            "        41,  1,  3,  3, 11, 17,  3,  3,  2,  4,  3,  4,  3, 10,  3,  3,  3, 20,\n",
            "         3, 12, 18, 21,  1, 17,  3,  3, 19, 20,  3, 19,  3, 21,  3,  3,  6, 35,\n",
            "        19,  3, 34, 36,  8, 21,  3,  4, 25,  4])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.]]), tensor([16, 16, 19,  3,  3,  4,  4, 19,  2,  4,  3,  4,  3,  3,  3, 20,  4, 26,\n",
            "         3,  3,  3,  3,  3,  4, 13,  3, 31, 16, 20,  3,  4, 19, 20, 11,  9,  1,\n",
            "         3,  3, 13,  3, 19,  1,  4,  4, 11,  3,  3,  4, 19,  3,  4,  4,  3,  3,\n",
            "        25,  4, 31,  4, 26, 11, 19,  4,  4,  4, 18,  3,  4,  4,  3, 10,  4, 19,\n",
            "         3,  3, 20,  3,  4, 19, 16,  3,  3,  4, 16,  4,  3,  3,  3,  3,  4, 10,\n",
            "         3, 25,  1,  3,  4, 16,  4,  4,  4, 16])]\n",
            "[tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 3, 11,  3, 19, 16,  3,  6,  3, 16,  3, 16, 21,  4,  3,  4,  1, 16,  4,\n",
            "         2,  3, 35,  3, 25,  8,  3,  3, 19,  3, 19,  4, 19,  3,  4,  3,  3, 19,\n",
            "         4, 19, 26,  3, 19, 24,  3,  3,  4,  3,  4,  3, 17,  4,  4,  3,  3,  3,\n",
            "        19, 43,  3,  9,  3,  4,  4, 10,  4, 21,  3,  3,  9,  3,  3, 11, 11,  1,\n",
            "         4,  1, 11,  3, 38,  3,  3,  3, 10,  3, 19, 16, 19, 20,  6,  3,  4, 39,\n",
            "         3, 44, 16,  3, 22,  3,  3, 16,  1, 19])]\n",
            "[tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.]]), tensor([ 4, 11,  9,  3,  4,  3,  3,  3,  1,  3,  3,  4, 13,  3,  3,  4,  3,  4,\n",
            "        24,  4,  3,  1, 24,  4,  3,  1, 41, 13,  3, 21,  1,  3,  3,  3,  3,  9,\n",
            "         4,  2, 19, 19, 32,  3,  4,  3,  4,  8, 19,  1,  3, 12, 19, 19, 34,  3,\n",
            "         4,  3,  3,  1, 39, 19,  4,  4,  4,  3,  4,  4, 22, 13,  4,  3, 19,  4,\n",
            "         4,  3, 20,  1,  4,  3,  3,  3,  3,  3, 16,  4, 11,  3, 19, 40,  4,  3,\n",
            "         3,  3,  3,  4,  4, 25,  6,  3,  4,  3])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 3,  3,  4,  1,  4,  4,  3,  4,  4,  4,  3,  1, 19, 41, 15,  4,  9,  1,\n",
            "         3, 11,  3,  3,  4, 21,  4, 19, 19, 13,  4, 44,  4, 13,  4, 20,  4,  4,\n",
            "         3, 19, 30, 26,  2, 24,  3, 37,  4, 20, 31,  4, 34,  3,  4,  3, 16, 31,\n",
            "        10,  3,  3, 19, 16, 32,  3, 20,  3,  3, 41, 11,  3,  4,  4,  8,  3,  8,\n",
            "        16,  3,  3,  4,  4, 19,  4,  3,  3, 16,  3,  3, 16,  4, 25, 36,  4, 28,\n",
            "         4, 19,  4,  3, 20,  3,  3, 16,  3, 36])]\n",
            "[tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 3, 18,  3,  3,  4, 20,  4,  3,  4, 11, 19, 20,  4,  4,  3,  3,  3,  4,\n",
            "         0,  1,  4,  3,  3,  1, 39,  3, 19, 36,  3, 11,  4,  3, 16,  3,  3,  3,\n",
            "         4, 35, 19,  3,  3,  3,  3,  3,  3, 16, 18,  3, 19,  1, 16,  4,  3,  3,\n",
            "         4,  3,  1,  1,  4, 22,  4, 19,  3, 12,  8,  3,  3,  4, 23,  3,  4,  4,\n",
            "         3,  4,  3,  3, 20,  1, 12,  3,  4, 16,  3, 16,  3,  3,  3,  1,  3, 19,\n",
            "        20,  4,  2,  3,  3, 20, 35, 11,  1,  4])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([11, 28, 13,  4,  3, 25,  3, 19,  3, 21, 23,  3,  3,  1,  8,  3,  3, 40,\n",
            "         3, 40,  4, 11,  4,  4,  4, 11,  3, 23,  3, 19,  3, 30,  3, 16,  3,  3,\n",
            "        19,  3,  4,  3,  4,  9,  3,  0, 42,  3,  4,  3, 16,  3,  4,  3,  3,  3,\n",
            "         4, 16,  3,  4,  4,  5, 11,  8,  3,  4,  3,  4,  3,  3, 16, 19,  3,  4,\n",
            "         3, 10,  3,  3,  3, 11,  3, 11,  0,  3, 24,  3,  1,  3, 13, 37,  3,  3,\n",
            "         3, 21, 10,  3,  4,  4,  3, 19,  4, 20])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 9,  4,  4,  3, 36,  4, 11,  4,  4,  3,  4,  3,  3,  3, 11,  1,  3,  3,\n",
            "        20,  1, 23, 20, 32,  3,  3,  3, 12,  3,  3, 11,  3,  3,  4, 19,  3,  3,\n",
            "        31, 10,  3,  3,  3,  1, 11,  3, 20,  6, 41,  4, 11,  9,  3,  3, 19, 27,\n",
            "        11,  8,  4,  3, 28, 11,  3, 16, 11,  4, 24, 16, 11, 10, 16,  3, 16, 19,\n",
            "        24,  3, 26, 32, 16, 19,  3,  3, 15,  3,  8,  3,  4,  1,  1, 13, 41,  4,\n",
            "        14, 23, 19,  3,  3,  3, 28, 11,  7,  4])]\n",
            "[tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 3,  8,  8, 19, 20,  4,  3,  4,  3,  3,  4, 33, 19,  3,  3,  3, 11, 21,\n",
            "         4,  4, 19,  3,  4,  3,  3, 19,  3,  3, 20,  3, 19, 19, 24, 28, 20,  3,\n",
            "        25,  5,  4, 20, 24,  4, 19,  4, 21,  4,  3,  4, 16,  1, 19,  1,  3,  4,\n",
            "         3,  3, 24,  8, 32, 25,  3, 16,  3,  3,  3, 16,  4,  3, 25,  3, 18,  3,\n",
            "        19,  3,  4,  3,  3, 16,  3,  4,  1,  6, 12, 11,  3,  3, 25,  4,  0,  3,\n",
            "        15, 19, 16,  3,  4,  3,  4,  3, 20,  3])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([13,  3, 29, 16,  4, 21,  4, 31,  3,  9,  3,  3,  4,  1,  3,  1,  4,  1,\n",
            "        13,  4,  9,  3,  3,  4, 11,  4,  4,  3,  3,  3, 20,  3,  3,  1,  4,  4,\n",
            "         3,  3, 17, 19,  3, 16, 31, 10,  3, 34,  3,  4,  4,  3, 16, 16,  3,  4,\n",
            "         3,  4, 25,  3, 26,  3,  3,  4, 24,  4, 40,  3,  3,  4,  4,  4,  3,  3,\n",
            "         2,  6,  3,  3,  3,  4,  3, 19,  4, 28,  3, 16,  4, 21,  1,  3,  4, 31,\n",
            "         8,  3,  4,  3,  3,  3,  4, 19,  3,  3])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 1,  3,  3,  3,  1, 25,  4,  4, 19,  9,  3,  8, 17,  4,  3,  4, 19,  3,\n",
            "         3,  3,  3,  4,  5, 19,  3, 17,  3, 20,  4,  3,  3, 17,  2,  3, 39, 10,\n",
            "         8,  1, 25,  3,  4,  3, 13,  3, 43, 11, 20, 33,  3,  3,  3,  3,  3,  6,\n",
            "        20,  8,  3, 12,  3,  3,  3,  3,  1,  3,  3, 20,  0,  4,  3,  6, 30,  3,\n",
            "         3,  3,  3,  4, 11,  4,  1,  4,  3, 20, 18, 19,  3,  3,  3,  4, 12,  3,\n",
            "        20, 26,  3, 19, 27, 23,  3, 11,  3, 18])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.]]), tensor([ 4,  4,  3,  3, 11,  3,  4,  8,  4,  8,  3,  3,  3,  4,  4,  3,  4,  3,\n",
            "         2,  3,  4,  3,  4,  4,  4, 15,  3,  4,  7, 19,  3, 19,  4,  4,  4,  3,\n",
            "         3,  3,  3, 19, 16,  3,  4,  3,  3,  4, 19, 16,  8, 16,  3, 44,  3, 11,\n",
            "        10,  3,  4,  4, 40,  4,  4,  3,  3, 19, 19, 16,  4,  4, 16, 11,  3,  2,\n",
            "        42,  1,  4, 25,  4, 11,  1, 19,  3, 25,  3,  3, 34,  3,  3,  1,  3,  3,\n",
            "         3,  4, 19, 13,  3,  4,  3,  3, 11, 18])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([16,  4, 20,  3,  4,  4,  4,  1,  3,  4,  4,  4,  3, 19, 13, 36,  4, 13,\n",
            "         4,  4,  3,  3,  4, 21, 13,  3,  3,  3, 25, 24,  4,  4,  7, 40,  3,  4,\n",
            "        38, 19,  3,  3,  4,  3, 19,  3,  4,  4, 13,  4, 11,  4, 15, 27,  4, 19,\n",
            "        16, 32,  3, 16,  3,  4,  1,  3,  4,  4, 30,  3, 13, 10, 16, 19, 11,  1,\n",
            "         3,  3,  3,  3, 11, 19, 20,  3,  4, 19,  3,  4,  3, 15, 21,  3, 21,  4,\n",
            "         6, 24,  4, 22,  1,  4,  3,  1,  4, 11])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([22, 16,  4,  3,  4,  3, 19,  4,  4,  1,  3, 19, 28,  3,  3,  4, 21,  3,\n",
            "         4,  8,  3,  3,  4, 16, 19,  3,  4,  0, 17,  3,  1,  3,  3,  3,  4,  3,\n",
            "         3,  6,  4, 16,  3,  4, 11,  1,  3,  3,  8, 25,  3,  3, 13,  4,  3,  4,\n",
            "         3,  3,  4,  3,  3, 13,  3,  3,  3,  4, 17,  4,  3,  3,  3, 19,  3, 16,\n",
            "         3,  4,  4, 16, 11,  9,  3, 23,  4,  3,  4,  3, 36,  4,  3,  3, 23, 19,\n",
            "        10,  1, 44,  3,  3, 25, 41,  3, 25,  3])]\n",
            "[tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 3,  3, 16, 16, 36, 38,  4, 11, 11,  3,  3, 20,  4, 16,  9, 19, 32, 19,\n",
            "         4,  9,  4, 10,  4, 20,  3, 41,  4,  3, 33,  3, 30,  1, 19,  3,  4, 20,\n",
            "         3,  4,  3,  8,  3, 13,  4, 11,  3, 16, 10,  4, 16,  4,  1, 13, 19,  3,\n",
            "         4, 16,  3,  3,  4,  1, 18,  1,  3,  4,  4, 20,  3,  3, 11, 31, 10,  4,\n",
            "        25, 25,  3,  1,  3,  3,  1,  3,  3, 16,  3, 21,  3,  3, 22, 19, 29, 20,\n",
            "         3,  3, 30,  4,  3,  3,  3, 11,  3,  3])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 3,  3, 20, 25,  4,  4,  3, 12, 19,  4, 19,  4,  3, 16,  9,  3,  4,  4,\n",
            "         3,  4,  3,  3,  3, 19,  2,  4,  3, 16,  3, 19, 11,  1,  3,  3,  3,  1,\n",
            "         4,  4, 11, 20,  3,  4, 33,  4, 16,  2,  4, 25,  4,  3,  3,  4,  3,  3,\n",
            "        20,  4,  3,  4,  3, 16,  3,  3,  3,  4,  4,  1, 19,  3,  3,  4,  4,  3,\n",
            "         1,  3,  3,  4, 25, 11,  8,  3, 28, 12, 29,  1,  3,  3,  4,  3,  4,  3,\n",
            "        25,  8,  3,  4,  4,  4,  0,  1, 31,  3])]\n",
            "[tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.]]), tensor([ 3,  1,  4,  3,  4,  3,  3,  3,  3, 11,  4,  3,  1, 20,  4,  8,  4,  3,\n",
            "        34, 17, 20, 15,  3, 13, 25,  4,  3, 21,  4,  4,  3,  3, 19, 43,  4,  3,\n",
            "         4,  1, 36, 10, 43,  3,  3, 12,  2,  3,  4,  1,  4,  4,  4,  8,  3,  3,\n",
            "         4,  4,  1,  3,  9, 11, 11, 16, 16,  6,  4,  4, 19, 16,  1, 16,  9,  1,\n",
            "         4,  4,  3,  4, 16,  0,  3, 14,  4,  4,  3,  3,  3,  3, 19,  2, 18, 20,\n",
            "        13,  4,  3,  3,  3,  1, 27,  3,  3,  3])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([30, 16,  8, 16,  4,  4,  9,  3,  3,  4, 19, 21,  9, 35,  4, 16, 11,  3,\n",
            "         4,  4,  4, 11, 24,  3,  3,  3, 18, 29, 16,  1,  3, 20,  4,  2,  4,  3,\n",
            "         1, 13,  4,  3,  3, 24,  8,  4, 31, 32, 10, 16, 16,  3, 30, 21,  3,  3,\n",
            "         4,  4,  3,  3, 12, 20,  3,  3,  4,  3, 44,  4,  3,  3,  4, 10, 20,  9,\n",
            "         3,  4,  4, 19,  3,  5, 19,  9,  1,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
            "         3,  3,  3,  3,  3, 30, 13,  3, 18,  3])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 0,  9, 28, 11,  4,  3, 19, 16, 16,  4, 13,  3,  4,  3,  4, 25,  4,  4,\n",
            "         4,  4,  3,  3, 21,  3,  3,  4,  3, 24, 11,  3,  4,  4,  4,  3,  4, 19,\n",
            "         4,  4, 18, 19, 13,  4, 16,  4,  3, 32,  4,  3,  3, 16, 20,  3,  4,  3,\n",
            "        10,  3, 11,  4,  3,  3,  3,  3,  3, 19,  4,  3, 20,  3, 16,  4,  4,  3,\n",
            "         3,  1,  3, 16,  3,  4,  3,  3,  4,  3, 42, 18,  3, 32,  3,  3,  4,  3,\n",
            "        13, 10,  2,  1,  4,  4,  3,  4,  4, 19])]\n",
            "[tensor([[0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 4,  4,  3, 11,  4, 16,  8,  3,  4,  3,  0, 20,  2,  3,  4, 25, 19,  3,\n",
            "        17,  3,  3,  3, 11, 16, 11,  3,  4,  3, 19,  3,  3, 19, 13,  3, 16,  3,\n",
            "         3, 11,  3, 19, 10,  1, 16, 23, 16,  1, 45, 19,  4,  4,  3,  3,  3, 20,\n",
            "        20,  4,  3, 19,  3,  8, 19,  3,  3, 25, 20, 30,  1,  0, 43,  3,  3,  3,\n",
            "         4, 19,  1,  3,  4,  4,  3,  4, 23,  3,  4,  3, 21,  3,  9,  3, 16,  3,\n",
            "        31, 18,  3,  8,  3,  8,  4,  3,  4,  1])]\n",
            "[tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([ 3,  3,  3,  3, 18,  4,  3,  3,  4,  4,  3,  4, 20,  4,  3,  3,  3, 16,\n",
            "        22, 35, 18,  3, 21,  4, 16,  6, 18,  3,  4,  3,  4,  4, 10, 20,  3,  3,\n",
            "        11, 19, 36,  4,  1,  3, 20, 17, 13,  3,  3,  3, 13,  0, 11,  1, 11,  3,\n",
            "         3,  3, 20,  4,  4,  3, 40,  1,  3, 20, 24, 11, 11, 16,  3, 40,  3, 36,\n",
            "        20,  3, 31, 11, 20, 40,  4,  3,  3,  3,  4,  4, 19, 19,  4,  4,  4,  1,\n",
            "         3,  4,  3,  3, 25, 12,  4, 10,  3, 11])]\n",
            "[tensor([[0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        ...,\n",
            "        [0., 1., 0.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.],\n",
            "        [0., 1., 1.,  ..., 0., 0., 0.]]), tensor([20,  3,  3,  4,  4,  4,  3,  3, 13, 30,  4,  3,  3, 19,  3,  8,  3, 10,\n",
            "         3, 15, 21, 13,  8, 30, 16,  3,  4, 20,  3, 13,  3,  3,  3, 11, 18,  2,\n",
            "         3, 16,  3,  3,  3,  3,  8,  3,  3, 24])]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjudrYzColns"
      },
      "source": [
        "## 2. Creación de red neuronal\n",
        "A continuación, crea tu red neuronal especificando una clase con los métodos constructor y forward"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1TOtwJKMn8sx"
      },
      "source": [
        "class RedNeuronal(nn.Module):\n",
        "  #Constructor es para definiciones de variables. Aquí recibimos como parámetro las dimensiones de la data de entrada\n",
        "  # y la cantidad de clases de salida\n",
        "  #OBS:Ocupo redes con 10000 para hacer match con el input\n",
        "  def __init__(self, input_dim, output_dim):\n",
        "    super().__init__()\n",
        "    self.fc1 = nn.Linear(input_dim, 10000)\n",
        "    self.fc2 = nn.Linear(10000, 5000)\n",
        "    self.fc3 = nn.Linear(5000, output_dim)    \n",
        "    #Aquí tienes que especificar la arquitectura de tu red.\n",
        "    \n",
        "  def forward(self, input):\n",
        "    #Aquí especificas lo que pasa cuando a la red se le pone datos\n",
        "    batch_size = input.shape[0]\n",
        "    #View modifica la forma de la data, para que el input tenga la forma  de batch_size\n",
        "    input = input.view(batch_size, -1)\n",
        "    h_1 = F.relu(self.fc1(input))\n",
        "    h_2 = F.relu(self.fc2(h_1))\n",
        "    y_pred = self.fc3(h_2)\n",
        "    #Retorna la salida de la red, y el vector de salida de la segunda capa (Para posterior analisis)\n",
        "    return y_pred, h_2"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YRCrQUaipdro"
      },
      "source": [
        "Luego, creas una instancia de tu red neuronal. A continuación debes especificar el tamaño de la entrada y el tamaño de la salida para instanciar tu red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mIc11MFUpMYT"
      },
      "source": [
        "# Creamos el modelo\n",
        "## Aquí tienes que cambiar estas dimensiones de acuerdo al problema a resolver\n",
        "INPUT_DIM = 10000\n",
        "OUTPUT_DIM = 46\n",
        "\n",
        "model = RedNeuronal(INPUT_DIM, OUTPUT_DIM)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IxAFYhzkp03V"
      },
      "source": [
        "Configuramos el optimizador y la función de Loss"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH48kdvFpsiS"
      },
      "source": [
        "#Crear el objeto para la optimización. \n",
        "optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "#Definir la función Loss\n",
        "#En Pytorch, CrossEntropyLoss incluye la activación Softmax y la función de costo \"negative log-likelihood\"\n",
        "#Van juntas por cuestiones de eficiencia\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "#En Pytorch nosotros decidimos dónde correr nuestro programa, así que inicializamos el \n",
        "# dispositivo dependiendo si tenemos un GPU o no\n",
        "\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "#Enviamos el modelo y la función Loss al GPU\n",
        "\n",
        "model = model.to(device)\n",
        "criterion = criterion.to(device)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PO6ORo8sNH1b"
      },
      "source": [
        "#Funciona para calcular el accuracy\n",
        "\n",
        "def calculate_accuracy(y_pred, y):\n",
        "  top_pred = y_pred.argmax(1, keepdim=True)\n",
        "  correct = top_pred.eq(y.view_as(top_pred)).sum()\n",
        "  acc = correct.float()/y.shape[0]\n",
        "  return acc"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IRtu06_7qcnx"
      },
      "source": [
        "## 3. Entrena tu red neuronal\n",
        "\n",
        "Entrena tu red neuronal usando Pytorch. Usa el ejemplo de clase para hacer el entrenamiento de tu red."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_NdouqgrXBT"
      },
      "source": [
        "#Se genera funcion de entrenamiento\n",
        "#Se usan como inputs todo lo generado anteriormente\n",
        "#iterator se ingresa la data de training generada con dataloader\n",
        "def train(model, iterator, optimizer, criterion, device):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "  #Poner la red en modo entrenamiento\n",
        "  model.train()\n",
        "  \n",
        "  #Training loop\n",
        "  #Se recorre toda la data con X:Valor de entrenamiento, Y:Etiqueta\n",
        "  for (x, y) in iterator:\n",
        "    x = x.to(device) #Data\n",
        "    y = y.long().to(device) #Labels\n",
        "        \n",
        "    optimizer.zero_grad() #Limpiar gradientes\n",
        "    #Enviar data a red      \n",
        "    y_pred, _ = model(x) \n",
        "    #Computar el loss    \n",
        "    loss = criterion(y_pred, y) \n",
        "    #Computar el accuracy   \n",
        "    acc = calculate_accuracy(y_pred, y) \n",
        "    #Computar gradientes    \n",
        "    loss.backward() \n",
        "    #Aplicar reglas de actualizacion    \n",
        "    optimizer.step() \n",
        "        \n",
        "    epoch_loss += loss.item()\n",
        "    epoch_acc += acc.item()\n",
        "        \n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pLYCWXZKNgdW"
      },
      "source": [
        "def evaluate(model, iterator, criterion, device):\n",
        "  epoch_loss = 0\n",
        "  epoch_acc = 0\n",
        "\n",
        "  model.eval()\n",
        "    \n",
        "  with torch.no_grad(): \n",
        "        \n",
        "    for (x, y) in iterator:\n",
        "      x = x.to(device)\n",
        "      y = y.long().to(device)\n",
        "\n",
        "      y_pred, _ = model(x)\n",
        "\n",
        "      loss = criterion(y_pred, y)\n",
        "\n",
        "      acc = calculate_accuracy(y_pred, y)\n",
        "\n",
        "      epoch_loss += loss.item()\n",
        "      epoch_acc += acc.item()\n",
        "  return epoch_loss / len(iterator), epoch_acc / len(iterator)\n",
        "\n",
        "def epoch_time(start_time, end_time):\n",
        "    elapsed_time = end_time - start_time\n",
        "    elapsed_mins = int(elapsed_time / 60)\n",
        "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
        "    return elapsed_mins, elapsed_secs"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk-UgWrYNj6s",
        "outputId": "8aa03953-c74f-4302-af07-70bfb92e72f1"
      },
      "source": [
        "EPOCHS = 30\n",
        "\n",
        "best_valid_loss = float('inf')\n",
        "train_loss_history = []\n",
        "val_loss_history = []\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    \n",
        "  start_time = time.time()\n",
        "\n",
        "  train_loss, train_acc = train(model, train_loader, optimizer, criterion, device)\n",
        "  valid_loss, valid_acc = evaluate(model, test_loader, criterion, device)\n",
        "\n",
        "  train_loss_history.append(train_loss)\n",
        "  val_loss_history.append(valid_loss)\n",
        "    \n",
        "  if valid_loss < best_valid_loss:\n",
        "    best_valid_loss = valid_loss\n",
        "    torch.save(model.state_dict(), 'saved-model.pt')\n",
        "    \n",
        "  end_time = time.time()\n",
        "\n",
        "  epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
        "    \n",
        "  print(f'Epoch: {epoch+1:02} | Epoch Time: {epoch_mins}m {epoch_secs}s')\n",
        "  print(f'\\tTrain Loss: {train_loss:.3f} | Train Acc: {train_acc*100:.2f}%')\n",
        "  print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. Acc: {valid_acc*100:.2f}%')"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 01 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 2.225 | Train Acc: 42.66%\n",
            "\t Val. Loss: 2.223 |  Val. Acc: 43.91%\n",
            "Epoch: 02 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 2.206 | Train Acc: 44.06%\n",
            "\t Val. Loss: 2.203 |  Val. Acc: 45.04%\n",
            "Epoch: 03 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 2.185 | Train Acc: 45.82%\n",
            "\t Val. Loss: 2.184 |  Val. Acc: 46.86%\n",
            "Epoch: 04 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 2.166 | Train Acc: 47.02%\n",
            "\t Val. Loss: 2.165 |  Val. Acc: 47.99%\n",
            "Epoch: 05 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 2.148 | Train Acc: 47.89%\n",
            "\t Val. Loss: 2.148 |  Val. Acc: 48.54%\n",
            "Epoch: 06 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 2.130 | Train Acc: 48.71%\n",
            "\t Val. Loss: 2.132 |  Val. Acc: 49.28%\n",
            "Epoch: 07 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 2.113 | Train Acc: 49.33%\n",
            "\t Val. Loss: 2.116 |  Val. Acc: 49.94%\n",
            "Epoch: 08 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 2.098 | Train Acc: 49.69%\n",
            "\t Val. Loss: 2.102 |  Val. Acc: 50.38%\n",
            "Epoch: 09 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 2.083 | Train Acc: 49.93%\n",
            "\t Val. Loss: 2.088 |  Val. Acc: 50.73%\n",
            "Epoch: 10 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 2.070 | Train Acc: 50.26%\n",
            "\t Val. Loss: 2.075 |  Val. Acc: 51.12%\n",
            "Epoch: 11 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 2.056 | Train Acc: 50.43%\n",
            "\t Val. Loss: 2.062 |  Val. Acc: 51.08%\n",
            "Epoch: 12 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 2.044 | Train Acc: 50.48%\n",
            "\t Val. Loss: 2.051 |  Val. Acc: 51.25%\n",
            "Epoch: 13 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 2.032 | Train Acc: 50.57%\n",
            "\t Val. Loss: 2.040 |  Val. Acc: 51.16%\n",
            "Epoch: 14 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 2.021 | Train Acc: 50.58%\n",
            "\t Val. Loss: 2.030 |  Val. Acc: 51.12%\n",
            "Epoch: 15 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 2.011 | Train Acc: 50.67%\n",
            "\t Val. Loss: 2.020 |  Val. Acc: 51.20%\n",
            "Epoch: 16 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 2.000 | Train Acc: 50.70%\n",
            "\t Val. Loss: 2.011 |  Val. Acc: 51.38%\n",
            "Epoch: 17 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 1.991 | Train Acc: 50.80%\n",
            "\t Val. Loss: 2.002 |  Val. Acc: 51.29%\n",
            "Epoch: 18 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 1.981 | Train Acc: 50.85%\n",
            "\t Val. Loss: 1.993 |  Val. Acc: 51.25%\n",
            "Epoch: 19 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 1.972 | Train Acc: 50.91%\n",
            "\t Val. Loss: 1.985 |  Val. Acc: 51.33%\n",
            "Epoch: 20 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 1.965 | Train Acc: 50.91%\n",
            "\t Val. Loss: 1.977 |  Val. Acc: 51.38%\n",
            "Epoch: 21 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 1.956 | Train Acc: 50.94%\n",
            "\t Val. Loss: 1.970 |  Val. Acc: 51.51%\n",
            "Epoch: 22 | Epoch Time: 0m 15s\n",
            "\tTrain Loss: 1.947 | Train Acc: 50.99%\n",
            "\t Val. Loss: 1.963 |  Val. Acc: 51.46%\n",
            "Epoch: 23 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 1.940 | Train Acc: 51.02%\n",
            "\t Val. Loss: 1.956 |  Val. Acc: 51.51%\n",
            "Epoch: 24 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 1.932 | Train Acc: 51.05%\n",
            "\t Val. Loss: 1.949 |  Val. Acc: 51.59%\n",
            "Epoch: 25 | Epoch Time: 0m 18s\n",
            "\tTrain Loss: 1.926 | Train Acc: 51.06%\n",
            "\t Val. Loss: 1.942 |  Val. Acc: 51.59%\n",
            "Epoch: 26 | Epoch Time: 0m 20s\n",
            "\tTrain Loss: 1.918 | Train Acc: 51.07%\n",
            "\t Val. Loss: 1.936 |  Val. Acc: 51.68%\n",
            "Epoch: 27 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 1.912 | Train Acc: 51.24%\n",
            "\t Val. Loss: 1.930 |  Val. Acc: 51.50%\n",
            "Epoch: 28 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 1.904 | Train Acc: 51.25%\n",
            "\t Val. Loss: 1.924 |  Val. Acc: 51.54%\n",
            "Epoch: 29 | Epoch Time: 0m 22s\n",
            "\tTrain Loss: 1.898 | Train Acc: 51.25%\n",
            "\t Val. Loss: 1.918 |  Val. Acc: 51.67%\n",
            "Epoch: 30 | Epoch Time: 0m 14s\n",
            "\tTrain Loss: 1.892 | Train Acc: 51.34%\n",
            "\t Val. Loss: 1.912 |  Val. Acc: 51.67%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "snrVLeJ8QDJ_",
        "outputId": "4e34dca8-36ad-4cfe-9647-d75280702825"
      },
      "source": [
        "#Visualizar las perdidas\n",
        "plt.figure()\n",
        "plt.plot(train_loss_history, color='b')\n",
        "plt.plot(val_loss_history, color='r')\n",
        "plt.show()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}